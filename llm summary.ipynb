{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720139ab-4c54-4e78-b2f8-7a038961fd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2941062-6e4d-4280-896e-b0a51e4b2c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740905b8-46a0-4da3-89c3-183000a2f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pdfplumber\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbae0a74-ba4b-41ec-a93d-bb7e4193fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "pdf_path='google_terms_of_service_en_in.pdf'\n",
    "\n",
    "output_text_file='extracted_text.txt'\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    extracted_text=\"\"\n",
    "    for page in pdf.pages:\n",
    "        extracted_text+=page.extract_text()\n",
    "\n",
    "with open(output_text_file, 'w') as text_file:\n",
    "    text_file.write(extracted_text)\n",
    "\n",
    "print(f\"Text extracted and saved to {output_text_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e75943c-4887-48fc-8c72-16259a69bb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading content\n",
    "\n",
    "with open('extracted_text.txt', 'r') as file:\n",
    "    document= file.read()\n",
    "\n",
    "#preview content \n",
    "print(document[:500])  #first 500 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e232607c-d765-4f44-9ee2-d67e2e36d1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarizing document\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "#loading summarization pipeline\n",
    "summarizer = pipeline('summarization', model='t5-small')\n",
    "\n",
    "summary = summarizer(document[:3000], max_length=200, min_length= 50, do_sample = False)\n",
    "\n",
    "print(f'summary:{summary}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f98943-74da-46ca-84e0-9b005b448bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "#split text into sentences\n",
    "sentences = sent_tokenize(document)\n",
    "\n",
    "print(sentences[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7e9f01-ec04-44f6-8400-e30da3ded5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine sentences into paragraphs\n",
    "\n",
    "paragraph=[]\n",
    "current_passage=''\n",
    "\n",
    "for sentence in sentences:\n",
    "    if len(current_passage.split())+len(sentence.split()) <200:            # adjusting the word limit\n",
    "        current_passage+=' '+ sentence\n",
    "    else:\n",
    "        paragraph.append(current_passage.strip())                       # if word count more then adding in next passage\n",
    "        current_passage= sentence\n",
    "\n",
    "if current_passage:\n",
    "    paragraph.append(current_passage.strip())                              # last passage included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a2ee7f-68cc-4c07-ad75-1f8274c37947",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdabe6f-5398-4cbf-9a44-1c43c8493246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the question generation pipeline\n",
    "qg  = pipeline(\"text2text-generation\", model=\"valhalla/t5-base-qg-hl\")\n",
    "\n",
    "# Function to generate 3 questions\n",
    "def generate_questions_pipeline(paragraph, min_questions=3):\n",
    "    input_text = paragraph\n",
    "    results = qg(input_text)\n",
    "    questions = results[0]['generated_text'].split('<sep>')\n",
    "\n",
    "    # Ensure at least 3 questions by generating more if needed\n",
    "    questions = [q.strip() for q in questions if q.strip()]\n",
    "    \n",
    "    while len(questions) < min_questions:\n",
    "        extra_results = qg(input_text)\n",
    "        extra_questions = extra_results[0]['generated_text'].split('<sep>')\n",
    "        questions.extend([q.strip() for q in extra_questions if q.strip()])\n",
    "        questions = list(set(questions))                                              # Remove duplicates\n",
    "    \n",
    "    return questions[:min_questions]                                                  # Return exactly 3 questions\n",
    "\n",
    "get_question= generate_questions_pipeline(paragraph, min_questions=3)\n",
    "print(get_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62718449-ac30-4734-93f1-e0a223992446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the QA pipeline\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
    "\n",
    "# function to track and answer only unique questions\n",
    "def answer_unique_questions(paragraph, qa_pipeline):\n",
    "    answered_questions = set()  # to store unique questions\n",
    "\n",
    "    for idx, passage in enumerate(paragraph):\n",
    "        questions = generate_questions_pipeline(paragraph)\n",
    "\n",
    "        for question in questions:\n",
    "            if question not in answered_questions:  # check if the question has already been answered\n",
    "                answer = qa_pipeline({'question': question, 'context': paragraph})\n",
    "                print(f\"Q: {question}\")\n",
    "                print(f\"A: {answer['answer']}\\n\")\n",
    "                answered_questions.add(question)  # add the question to the set to avoid repetition\n",
    "        print(f\"{'='*50}\\n\")\n",
    "              \n",
    "answer_unique_questions(paragraph, qa_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6c7bf7-aea2-4a69-9796-2f7d8604b709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959fd843-9bc8-4867-b54b-7e18b3fc1064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd37b2f6-5ef7-4391-86c8-400554eeaebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b29c33f-87ad-459b-b60a-2b4bdf2f2eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad75fb82-ef19-47f3-976c-7fa6ffc29d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16040871-de5a-4485-ad3c-538e3e000f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a9852a-1bae-4df7-816d-c5f30fe61896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61627d6b-8912-44bb-ad9d-9038ba60e6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e12084c-32d7-4879-8477-9be4f0782eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7898e734-efb4-47b3-8320-8147d9948dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4214ea92-816a-4176-9348-bb461f4a272a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
